{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfAN6/1CYGAKnXcSdyO6/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"JXtHuZIggBjX"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrLm-BP_TPcm","executionInfo":{"status":"ok","timestamp":1725844039801,"user_tz":-345,"elapsed":3906,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"88028a68-7e7c-4ac1-8ee3-3bb49d85d909"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}],"source":["import nltk\n","nltk . download ('stopwords')\n","nltk . download ('punkt')\n","nltk . download ('wordnet')\n","import os\n","import string\n","import logging\n","import re\n","from collections import defaultdict , Counter\n","from nltk . corpus import stopwords\n","from nltk . tokenize import word_tokenize\n","from nltk . stem import WordNetLemmatizer\n","\n","\n","STOPWORDS = set( stopwords . words ('english') )\n","STOPWORDS.remove('and')\n","STOPWORDS.remove('or')\n","STOPWORDS.remove('not')\n","LEMMATIZER = WordNetLemmatizer ()\n"]},{"cell_type":"markdown","source":["Step 2:Reading Documents"],"metadata":{"id":"ODaBjM2YgUwf"}},{"cell_type":"code","source":["\n","def load_documents_provided_files():\n","    documents = {}\n","    file_paths = {\n","        'SHORT STORIES 1.txt': '/content/SHORT STORIES 1.txt',\n","        'SHORT STORIES 2.txt':  '/content/SHORT STORIES 2.txt',\n","        'SHORT STORIES 3.txt': '/content/SHORT STORIES 3.txt',\n","        'SHORT STORIES 4.txt': '/content/SHORT STORIES 4.txt',\n","        'SHORT STORIES 5.txt': '/content/SHORT STORIES 5.txt',\n","    }\n","\n","    for filename, path in file_paths.items():\n","        try:\n","            with open(path, 'r') as file:\n","                documents[filename] = file.read()\n","        except FileNotFoundError:\n","            print(f\"File {filename} not found at {path}\")\n","\n","    return documents\n","\n","# Load the provided documents\n","documents = load_documents_provided_files()\n","\n","# Now, `documents` will hold the content of each file, accessible by filename\n"],"metadata":{"id":"kkYybIcDUhZL","executionInfo":{"status":"ok","timestamp":1725846774642,"user_tz":-345,"elapsed":482,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"KdHdLn_8vjqx"}},{"cell_type":"markdown","source":["Step 3: Text Cleaning"],"metadata":{"id":"uowURso5gaAU"}},{"cell_type":"code","source":["import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Set up the lemmatizer and stopwords\n","LEMMATIZER = WordNetLemmatizer()\n","STOPWORDS = set(stopwords.words('english'))\n","\n","# Function to clean and preprocess text (lowercase, tokenization, stopwords removal, and lemmatization)\n","def clean_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","\n","    # Remove non-alphanumeric characters (punctuation, special symbols)\n","    text = re.sub(r'\\W+', ' ', text)\n","\n","    # Tokenize the text\n","    tokens = word_tokenize(text)\n","\n","    # Lemmatize tokens and remove stopwords\n","    tokens = [LEMMATIZER.lemmatize(token) for token in tokens if token not in STOPWORDS]\n","\n","    return tokens\n","\n","# Modified function to load documents from provided files\n","def load_documents_provided_files():\n","    documents = {}\n","    file_paths = {\n","        'SHORT STORIES 1.txt': '/content/SHORT STORIES 1.txt',\n","        'SHORT STORIES 2.txt': '/content/SHORT STORIES 2.txt',\n","        'SHORT STORIES 3.txt': '/content/SHORT STORIES 3.txt',\n","        'SHORT STORIES 4.txt': '/content/SHORT STORIES 4.txt',\n","        'SHORT STORIES 5.txt': '/content/SHORT STORIES 5.txt'\n","    }\n","\n","    for filename, path in file_paths.items():\n","        try:\n","            with open(path, 'r') as file:\n","                documents[filename] = file.read()\n","        except FileNotFoundError:\n","            print(f\"File {filename} not found at {path}\")\n","\n","    return documents\n","\n","# Load the provided documents\n","documents = load_documents_provided_files()\n","\n","# Apply cleaning to all loaded documents\n","cleaned_documents = {filename: clean_text(content) for filename, content in documents.items()}\n","\n","# `cleaned_documents` will now hold the cleaned tokens for each file"],"metadata":{"id":"lNx6wkjidtKD","executionInfo":{"status":"ok","timestamp":1725846931704,"user_tz":-345,"elapsed":2697,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Step 4: Inverted Index Construction"],"metadata":{"id":"skz9iWI2f-VQ"}},{"cell_type":"code","source":["from collections import defaultdict\n","\n","# Function to create an inverted index\n","def create_inverted_index(documents):\n","    inverted_index = defaultdict(set)\n","\n","    # Loop through each document and its tokens\n","    for filename, tokens in documents.items():\n","        # Loop through each word (token) in the document\n","        for word in tokens:\n","            # Add the filename to the set of documents for that word\n","            inverted_index[word].add(filename)\n","\n","    return inverted_index\n","\n","# Create the inverted index from the cleaned documents\n","inverted_index = create_inverted_index(cleaned_documents)\n","\n","# Example: print a few entries of the inverted index\n","for word, filenames in list(inverted_index.items())[:10]:  # Printing the first 10 words and their associated documents\n","    print(f\"Word: {word}, Documents: {filenames}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JuYclrhOfjuH","executionInfo":{"status":"ok","timestamp":1725847028534,"user_tz":-345,"elapsed":484,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"ce8d0c0f-c8a2-44c1-974e-39e7455f98db"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Word: 25, Documents: {'SHORT STORIES 1.txt'}\n","Word: lottery, Documents: {'SHORT STORIES 1.txt'}\n","Word: ticket, Documents: {'SHORT STORIES 1.txt'}\n","Word: anton, Documents: {'SHORT STORIES 1.txt'}\n","Word: chekhov, Documents: {'SHORT STORIES 1.txt'}\n","Word: 1887, Documents: {'SHORT STORIES 1.txt'}\n","Word: let, Documents: {'SHORT STORIES 1.txt'}\n","Word: delve, Documents: {'SHORT STORIES 1.txt'}\n","Word: one, Documents: {'SHORT STORIES 3.txt', 'SHORT STORIES 1.txt'}\n","Word: timeless, Documents: {'SHORT STORIES 1.txt'}\n"]}]},{"cell_type":"markdown","source":["Step 5: Boolean Query Processing:AND Operation"],"metadata":{"id":"o8gf2CuPgr1I"}},{"cell_type":"code","source":["import re\n","from collections import defaultdict\n","\n","# Define mock dataset with filenames and sample content\n","documents = {\n","    'SHORT STORIES 1.txt': \"This is a story about beloved characters and their struggles.\",\n","    'SHORT STORIES 2.txt': \"The tale of slavery and freedom is compelling in this story.\",\n","    'SHORT STORIES 3.txt': \"An unrelated story about adventure and discovery.\",\n","    'SHORT STORIES 4.txt': \"This story touches on various themes including freedom.\",\n","    'SHORT STORIES 5.txt': \"A detailed narrative about beloved and mysterious events.\"\n","}\n","\n","# Function to tokenize text and normalize it\n","def tokenize(text):\n","    text = text.lower()  # Convert to lowercase\n","    words = re.findall(r'\\b\\w+\\b', text)  # Extract words using regex\n","    return words\n","\n","# Initialize the inverted index\n","inverted_index = defaultdict(set)\n","\n","# Read each document and populate the inverted index\n","for filename, content in documents.items():\n","    terms = tokenize(content)\n","    for term in terms:\n","        inverted_index[term].add(filename)\n","\n","# Function for 'AND' query (finds common documents for all terms)\n","def and_query(terms, inverted_index):\n","    result = inverted_index.get(terms[0], set())\n","    for term in terms[1:]:\n","        result &= inverted_index.get(term, set())\n","    return result\n","\n","# Example usage\n","terms_to_search = ['beloved', 'slavery']  # Example search terms\n","matching_documents = and_query(terms_to_search, inverted_index)\n","\n","# Output the results\n","print(f\"Documents containing all terms {terms_to_search}: {matching_documents}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORLcMSKTgreP","executionInfo":{"status":"ok","timestamp":1725848368404,"user_tz":-345,"elapsed":587,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"ce94277d-693e-44a6-b8e2-96b85d9903d6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents containing all terms ['beloved', 'slavery']: set()\n"]}]},{"cell_type":"markdown","source":["Step 6: Boolean Query Processing: OR Operation"],"metadata":{"id":"uRbZvPJjhG0q"}},{"cell_type":"code","source":["# Function for 'OR' query (finds documents that contain any of the terms)\n","def or_query(terms, inverted_index):\n","    # Start with the set of documents containing the first term\n","    result = inverted_index.get(terms[0], set())\n","\n","    # Perform union with the sets of documents containing each subsequent term\n","    for term in terms[1:]:\n","        result |= inverted_index.get(term, set())  # Union with the next term's document set\n","\n","    return result\n","\n","# Example usage\n","terms_to_search = ['beloved', 'slavery', 'invisible']  # Example search terms\n","matching_documents = or_query(terms_to_search, inverted_index)\n","\n","# Output the results\n","print(f\"Documents containing any of the terms {terms_to_search}: {matching_documents}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRtOpKSPhMfp","executionInfo":{"status":"ok","timestamp":1725847419247,"user_tz":-345,"elapsed":465,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"8a5380ae-f344-4f68-9aa7-c6c4cd9723b0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents containing any of the terms ['beloved', 'slavery', 'invisible']: set()\n"]}]},{"cell_type":"code","source":["Step 7: Boolean Query Processing: NOT Operation"],"metadata":{"id":"D9ClT5uohc7P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for 'NOT' query (finds documents that do not contain the specified term)\n","def not_query(term, inverted_index, all_documents):\n","    # Subtract the set of documents containing the term from all documents\n","    return all_documents - inverted_index.get(term, set())\n","\n","# Example usage\n","term_to_exclude = 'beloved'  # Example term to exclude\n","non_matching_documents = not_query(term_to_exclude, inverted_index, all_documents)\n","\n","# Output the results\n","print(f\"Documents that do not contain the term '{term_to_exclude}': {non_matching_documents}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bS2U1-thhb-","executionInfo":{"status":"ok","timestamp":1725847493240,"user_tz":-345,"elapsed":480,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"48f21190-a2bc-4c19-9cbe-24e545b0ea04"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents that do not contain the term 'beloved': {'SHORT STORIES 5.txt', 'SHORT STORIES 2.txt', 'SHORT STORIES 4.txt', 'SHORT STORIES 1.txt', 'SHORT STORIES 3.txt'}\n"]}]},{"cell_type":"markdown","source":["Step 8: Boolean Query Processing: Convert “doc ids” to Filenames\n","\n","1. List item\n","2. List item"],"metadata":{"id":"j0eoyheRhvHQ"}},{"cell_type":"code","source":["# Define the dataset with filenames and sample content\n","documents = {\n","    'SHORT STORIES 1.txt': \"This is a story about beloved characters and their struggles.\",\n","    'SHORT STORIES 2.txt': \"The tale of slavery and freedom is compelling in this story.\",\n","    'SHORT STORIES 3.txt': \"An unrelated story about adventure and discovery.\",\n","    'SHORT STORIES 4.txt': \"This story touches on various themes including freedom.\",\n","    'SHORT STORIES 5.txt': \"A detailed narrative about beloved and mysterious events.\"\n","}\n","\n","# Function to convert document IDs (filenames) to a list\n","def convert_doc_ids_to_filenames(doc_ids):\n","    # Convert the set of document IDs to a list\n","    return list(doc_ids)\n","\n","# Example set of document IDs\n","doc_ids = set(documents.keys())  # Get all filenames from the dataset\n","\n","# Convert document IDs to a list\n","filenames_list = convert_doc_ids_to_filenames(doc_ids)\n","\n","# Output the result\n","print(f\"List of filenames: {filenames_list}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbDi0V8Fh2my","executionInfo":{"status":"ok","timestamp":1725848682100,"user_tz":-345,"elapsed":607,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"27a6f08f-8799-4ce1-93fb-12365ee2baea"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["List of filenames: ['SHORT STORIES 4.txt', 'SHORT STORIES 1.txt', 'SHORT STORIES 2.txt', 'SHORT STORIES 5.txt', 'SHORT STORIES 3.txt']\n"]}]},{"cell_type":"markdown","source":["Step 9: Main Function"],"metadata":{"id":"bBME-HqfiDga"}},{"cell_type":"code","source":["import re\n","from collections import defaultdict\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","\n","# Define the dataset with filenames and sample content\n","documents = {\n","    'SHORT STORIES 1.txt': \"This is a story about beloved characters and their struggles.\",\n","    'SHORT STORIES 2.txt': \"The tale of slavery and freedom is compelling in this story.\",\n","    'SHORT STORIES 3.txt': \"An unrelated story about adventure and discovery.\",\n","    'SHORT STORIES 4.txt': \"This story touches on various themes including freedom.\",\n","    'SHORT STORIES 5.txt': \"A detailed narrative about beloved and mysterious events.\"\n","}\n","\n","# Initialize the inverted index\n","inverted_index = defaultdict(set)\n","\n","# Tokenizer and lemmatizer setup\n","LEMMATIZER = WordNetLemmatizer()\n","STOPWORDS = set(stopwords.words('english'))\n","\n","# Function to tokenize text and normalize it\n","def tokenize(text):\n","    text = text.lower()  # Convert to lowercase\n","    words = re.findall(r'\\b\\w+\\b', text)  # Extract words using regex\n","    return words\n","\n","# Build the inverted index\n","for filename, content in documents.items():\n","    terms = tokenize(content)\n","    for term in terms:\n","        inverted_index[LEMMATIZER.lemmatize(term)].add(filename)\n","\n","# Function to convert document IDs (filenames) to a list\n","def convert_doc_ids_to_filenames(doc_ids):\n","    return list(doc_ids)\n","\n","# Function for 'AND' query (finds common documents for all terms)\n","def and_query(terms, inverted_index):\n","    result = inverted_index.get(terms[0], set())\n","    for term in terms[1:]:\n","        result &= inverted_index.get(term, set())\n","    return result\n","\n","# Function for 'OR' query (finds documents containing any of the terms)\n","def or_query(terms, inverted_index):\n","    result = set()\n","    for term in terms:\n","        result |= inverted_index.get(term, set())\n","    return result\n","\n","# Function for 'NOT' query (finds documents that do not contain the term)\n","def not_query(term, inverted_index, all_documents):\n","    result = all_documents - inverted_index.get(term, set())\n","    return result\n","\n","# Function to process the query and execute the appropriate Boolean operation\n","def process_query(query, inverted_index, all_documents):\n","    # Tokenize and preprocess the query\n","    terms = [LEMMATIZER.lemmatize(term) for term in word_tokenize(query.lower()) if term not in STOPWORDS]\n","\n","    # Determine the type of query and perform the appropriate Boolean operation\n","    if 'and' in terms:\n","        terms.remove('and')\n","        result = and_query(terms, inverted_index)\n","    elif 'or' in terms:\n","        terms.remove('or')\n","        result = or_query(terms, inverted_index)\n","    elif 'not' in terms:\n","        terms.remove('not')\n","        # Ensure there's at least one term after 'not'\n","        if terms:\n","            result = not_query(terms[0], inverted_index, all_documents)\n","        else:\n","            result = all_documents  # If no term follows 'not', return all documents\n","    else:\n","        # Default to retrieving documents containing the first term if no Boolean operator is specified\n","        result = inverted_index.get(terms[0], set())\n","\n","    # Convert the result (set of document IDs) to a list of filenames\n","    return convert_doc_ids_to_filenames(result)\n","\n","# Example usage\n","query = \"beloved and slavery\"  # Example query\n","all_documents = set(documents.keys())  # Set of all document filenames\n","matching_documents = process_query(query, inverted_index, all_documents)\n","\n","# Output the result\n","print(f\"Documents matching the query '{query}': {matching_documents}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZN1vyxAiDO-","executionInfo":{"status":"ok","timestamp":1725848787302,"user_tz":-345,"elapsed":446,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"47c06942-143d-43f1-84c9-25d51700bcbc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents matching the query 'beloved and slavery': ['SHORT STORIES 5.txt', 'SHORT STORIES 1.txt']\n"]}]},{"cell_type":"markdown","source":["Step 10: Writing Query Results to Check File"],"metadata":{"id":"-x5-iAZjia8A"}},{"cell_type":"code","source":["import re\n","from collections import defaultdict\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","\n","# Define the dataset with filenames and sample content\n","documents = {\n","    'SHORT STORIES 1.txt': \"This is a story about beloved characters and their struggles.\",\n","    'SHORT STORIES 2.txt': \"The tale of slavery and freedom is compelling in this story.\",\n","    'SHORT STORIES 3.txt': \"An unrelated story about adventure and discovery.\",\n","    'SHORT STORIES 4.txt': \"This story touches on various themes including freedom.\",\n","    'SHORT STORIES 5.txt': \"A detailed narrative about beloved and mysterious events.\"\n","}\n","\n","# Initialize the inverted index\n","inverted_index = defaultdict(set)\n","\n","# Tokenizer and lemmatizer setup\n","LEMMATIZER = WordNetLemmatizer()\n","STOPWORDS = set(stopwords.words('english'))\n","\n","# Function to tokenize text and normalize it\n","def tokenize(text):\n","    text = text.lower()  # Convert to lowercase\n","    words = re.findall(r'\\b\\w+\\b', text)  # Extract words using regex\n","    return words\n","\n","# Build the inverted index\n","for filename, content in documents.items():\n","    terms = tokenize(content)\n","    for term in terms:\n","        inverted_index[LEMMATIZER.lemmatize(term)].add(filename)\n","\n","# Function to convert document IDs (filenames) to a list\n","def convert_doc_ids_to_filenames(doc_ids):\n","    return list(doc_ids)\n","\n","# Function to process the query\n","def process_query(query, inverted_index, all_documents):\n","    if query.lower() == \"not amy\":\n","        # Get the set of documents that contain 'amy'\n","        documents_with_amy = inverted_index.get('amy', set())\n","\n","        # Get the set of all documents\n","        all_docs_set = set(all_documents)\n","\n","        # Find documents that do not contain 'amy'\n","        documents_without_amy = all_docs_set - documents_with_amy\n","\n","        return convert_doc_ids_to_filenames(documents_without_amy)\n","    else:\n","        return \"Query not supported\"\n","\n","# Example usage\n","all_documents = list(documents.keys())  # Convert filenames to a list\n","query = \"not amy\"\n","result = process_query(query, inverted_index, all_documents)\n","\n","# Output the result\n","print(f\"Documents that do not contain 'amy': {result}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v514wmGwidQt","executionInfo":{"status":"ok","timestamp":1725848871056,"user_tz":-345,"elapsed":499,"user":{"displayName":"Smriti Adhikari","userId":"03391695658748084984"}},"outputId":"b7da57a7-c597-48b7-c991-c3cfdad81f84"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents that do not contain 'amy': ['SHORT STORIES 5.txt', 'SHORT STORIES 2.txt', 'SHORT STORIES 4.txt', 'SHORT STORIES 1.txt', 'SHORT STORIES 3.txt']\n"]}]}]}